{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 일단 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 16:52:32.352610: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-28 16:52:32.504234: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-28 16:52:33.196533: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.3/lib64\n",
      "2022-11-28 16:52:33.196593: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.3/lib64\n",
      "2022-11-28 16:52:33.196598: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 리스트 형을 텐서로~ int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 16:53:02.869278: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 16:53:02.874635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 16:53:02.874871: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 16:53:02.875711: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-28 16:53:02.876206: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 16:53:02.876708: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 16:53:02.877128: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 16:53:03.313586: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 16:53:03.313855: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 16:53:03.313997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 16:53:03.314177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 41 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_ten = tf.constant([1, 2, 3])\n",
    "li_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 혹은 float형 텐서로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_ten_f = tf.constant([1., 2., 3.])\n",
    "li_ten_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 혹은 튜플을 텐서로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 2, 3],\n",
       "       [1, 2, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tu_ten = tf.constant(((1, 2, 3), (1, 2, 3)))\n",
    "tu_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 넘파이를 텐서로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 2., 3.])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([1., 2., 3.])\n",
    "arr_ten = tf.constant(arr)\n",
    "arr_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 텐서를 numpy로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3.]), numpy.ndarray)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_ten.numpy(), type(arr_ten.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 shape이나 dtype을 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([3]), TensorShape([2, 3]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_ten.shape, tu_ten.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 방금처럼 텐서로 지정하거나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tf.constant([1, 2, 3], dtype=tf.float32)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 cast를 사용하거나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int16, numpy=array([1, 2, 3], dtype=int16)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(tensor, dtype=tf.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10 1로 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 0으로 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros((2, 5), dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12 텐서플로우에도 range가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.range(1, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.13 텐서로 등비수열 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometric_sequence(n):\n",
    "    r = tf.range(n, dtype='int32')\n",
    "    s = tf.ones(n, dtype=tf.int32) * 2\n",
    "    return s**r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.14 여기서 알아야할 것은 코딩 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([  1   2   4   8  16  32  64 128 256 512], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(geometric_sequence(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.15 랜덤 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[-0.33519897, -0.44111612, -1.9443173 ],\n",
       "       [-0.0290526 , -0.04916233,  1.373018  ],\n",
       "       [-0.05720217,  0.33631656, -0.27425495]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (3, 3)\n",
    "tf.random.normal(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.16 텐서플로우에서 랜덤시드 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.5983684], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.53933334], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(13)\n",
    "a = tf.random.uniform([1])\n",
    "b = tf.random.uniform([1])\n",
    "print(a, b, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.17 한번더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.27229798], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.5121772], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform([1])\n",
    "b = tf.random.uniform([1])\n",
    "print(a, b, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.18 시드 설정의 경이로움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.5983684], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.53933334], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(13)\n",
    "a = tf.random.uniform([1])\n",
    "b = tf.random.uniform([1])\n",
    "print(a, b, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 변수로 선언하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=int64, numpy=\n",
      "array([[1, 2],\n",
      "       [3, 4]])>\n",
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
      "array([[1, 2],\n",
      "       [3, 4]], dtype=int32)>\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "arr = np.array([[1, 2], [3, 4]])\n",
    "li = [[1, 2], [3, 4]]\n",
    "\n",
    "te_var = tf.Variable(tensor)\n",
    "arr_var = tf.Variable(arr)\n",
    "li_var = tf.Variable(li)\n",
    "\n",
    "print(te_var)\n",
    "print(arr_var)\n",
    "print(li_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 뭐 변수라도 확인할 수 있는건 다 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (2, 2)\n",
      "DType:  <dtype: 'float32'>\n",
      "AsNumPy:  <bound method BaseResourceVariable.numpy of <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>>\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape: \", te_var.shape)\n",
    "print(\"DType: \", te_var.dtype)\n",
    "print(\"AsNumPy: \", te_var.numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 메모리를 허비하지 않고 재할당 가능하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First :  <tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([2., 3.], dtype=float32)> \n",
      "\n",
      "Second :  <tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([2.0, 3.0])\n",
    "print(\"First : \", a, \"\\n\")\n",
    "\n",
    "a.assign([1, 2])\n",
    "print(\"Second : \", a, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 텐서 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 덧셈 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([2, 3, 4, 5, 6, 7], dtype=int32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.range(6, dtype=tf.int32)\n",
    "b = 2 * tf.ones(6, dtype=tf.int32)\n",
    "\n",
    "tf.add(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 사실"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([2, 3, 4, 5, 6, 7], dtype=int32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 연산의 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.abs : 절대값\n",
    "- tf.sign : 부호\n",
    "- tf.round : 반올림\n",
    "- tf.ceil : 올림\n",
    "- tf.floor : 내림\n",
    "- tf.square : 제곱\n",
    "- tf.sqrt : 제곱근\n",
    "- tf.maximum : 두 텐서의 각 원소에서 최댓값만 반환\n",
    "- tf.minimum : 두 텐서의 각 원소에서 최솟값만 반환\n",
    "- tf.cumsum : 누적합\n",
    "- tf.cumprod :누적곱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 최대값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([2, 2, 2, 3, 4, 5], dtype=int32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.maximum(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 연습용 텐서 하나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[-0.9487271 ,  1.3044667 , -1.1531729 ],\n",
       "       [-0.28560743,  0.48564127, -0.9099395 ],\n",
       "       [-0.96096003,  1.3391656 , -0.11258006]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2 = tf.random.normal((3, 3))\n",
    "rank_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 첫번째 행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-0.9487271,  1.3044667, -1.1531729], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 첫번째 열, 첫번째 행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-0.9487271>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 3차원 짜리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3, 3), dtype=float32, numpy=\n",
       "array([[[-0.1856016 , -1.1418061 ,  0.0194767 ],\n",
       "        [-2.7855177 ,  1.2621061 , -1.2295452 ],\n",
       "        [-0.9714309 , -0.35085803,  1.1138306 ]],\n",
       "\n",
       "       [[ 0.9682026 , -1.9595007 ,  1.0642354 ],\n",
       "        [ 1.494038  , -1.1601017 ,  1.4813476 ],\n",
       "        [-0.21271256,  1.0881292 ,  0.31397238]],\n",
       "\n",
       "       [[-0.52992046,  0.19140598, -0.2779634 ],\n",
       "        [-1.2172662 ,  0.5619219 , -2.132913  ],\n",
       "        [ 0.8605408 ,  0.65008086,  0.33721906]]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_3 = tf.random.normal((3, 3, 3))\n",
    "rank_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 4차원 짜리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3, 3, 3), dtype=float32, numpy=\n",
       "array([[[[ 1.3927455 , -0.45965314,  0.49407616],\n",
       "         [ 0.17237075,  0.93350935,  1.6913122 ],\n",
       "         [ 0.91713065, -0.16278401,  0.3994191 ]],\n",
       "\n",
       "        [[ 1.3299477 , -0.16608767,  0.52453625],\n",
       "         [-0.825861  , -0.39364755,  0.15490197],\n",
       "         [-0.7261836 , -0.21677208,  0.14307553]],\n",
       "\n",
       "        [[-0.7616838 , -1.7694571 , -1.2084615 ],\n",
       "         [ 0.15294294,  0.61789715,  0.75220877],\n",
       "         [-0.9087012 ,  0.34433067, -0.1459559 ]]],\n",
       "\n",
       "\n",
       "       [[[ 2.2195857 , -0.9483894 , -0.72741896],\n",
       "         [-0.09788546, -0.74635005,  1.6196522 ],\n",
       "         [-1.339364  ,  0.10365214,  1.5238657 ]],\n",
       "\n",
       "        [[ 1.970443  , -1.9742427 ,  1.646089  ],\n",
       "         [-0.10265194, -0.14842309,  0.6076201 ],\n",
       "         [ 0.31007034, -0.16753197, -0.6445421 ]],\n",
       "\n",
       "        [[-0.11728214, -0.38824674,  0.31977358],\n",
       "         [-0.8027508 , -1.8807936 ,  0.35686776],\n",
       "         [-1.498092  , -1.8625052 ,  1.2523474 ]]],\n",
       "\n",
       "\n",
       "       [[[ 1.9372497 , -1.0422333 , -0.896427  ],\n",
       "         [-0.2374812 , -0.6838861 , -1.3482342 ],\n",
       "         [ 0.41981524,  0.6032611 , -2.714812  ]],\n",
       "\n",
       "        [[-1.3464243 , -1.1303519 ,  0.9735961 ],\n",
       "         [ 0.5794143 , -0.42320266, -1.8371418 ],\n",
       "         [-0.08561901, -1.5159502 ,  0.37542394]],\n",
       "\n",
       "        [[-1.120613  ,  0.29542217, -0.54509264],\n",
       "         [-1.2684476 , -1.0359796 ,  1.9996897 ],\n",
       "         [-0.7616689 , -1.2454214 ,  0.05226924]]]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4 = tf.random.normal((3, 3, 3, 3))\n",
    "rank_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10 차원의 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.reduce_mean : 설정한 축의 평균을 구한다. \n",
    "- tf.reduce_max : 설정한 축의 최댓값을 구한다.\n",
    "- tf.reduce_min : 설정한 축의 최솟값을 구한다.\n",
    "- tf.reduce_prod : 설정한 축의 요소를 모두 곱한 값을 구한다.\n",
    "- tf.reduce_sum : 설정한 축의 요소를 모두 더한 값을 구한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11 행렬곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 17:13:29.700911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[2, 0], [0, 1]], dtype=tf.float32)\n",
    "b = tf.constant([[1, 1], [1, 1]], dtype=tf.float32)\n",
    "tf.matmul(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11 행렬곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 17:13:49.899384: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x1b4bdeb0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.5, 0. ],\n",
       "       [0. , 1. ]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[2, 0], [0, 1]], dtype=tf.float32)\n",
    "tf.linalg.inv(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.13 크기나 차원을 변경하는 명령"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.reshape : 벡터 행렬의 크기 반환\n",
    "- tf.transpose : 전치 연산\n",
    "- tf.expand_dims : 지정한 축으로 차원을 추가\n",
    "- tf.squeeze : 벡처로 차원을 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.14 테스트용 하나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    : tf.Tensor([0. 1. 2. 3. 4. 5.], shape=(6,), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = tf.range(6, dtype=tf.float32)\n",
    "print(\"a    :\", a, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.15 행령의 크기 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a     : tf.Tensor([0. 1. 2. 3. 4. 5.], shape=(6,), dtype=float32)\n",
      "a_2d  : tf.Tensor(\n",
      "[[0. 1. 2.]\n",
      " [3. 4. 5.]], shape=(2, 3), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a_2d = tf.reshape(a, (2, 3)) # 1차원 벡터는 2X3 크기의 2차원 행렬로 변환\n",
    "print(\"a     :\", a)\n",
    "print(\"a_2d  :\", a_2d, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.16 전치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_2d     : tf.Tensor(\n",
      "[[0. 1. 2.]\n",
      " [3. 4. 5.]], shape=(2, 3), dtype=float32)\n",
      "a_2d_t: tf.Tensor(\n",
      "[[0. 3.]\n",
      " [1. 4.]\n",
      " [2. 5.]], shape=(3, 2), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a_2d_t = tf.transpose(a_2d) # 2X3 크기의 2차원 행렬을 3X2 크기의 2차원 행렬로 변환\n",
    "print(\"a_2d     :\", a_2d)\n",
    "print(\"a_2d_t:\", a_2d_t, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.17 첫번째 차원 늘리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_2d     : tf.Tensor(\n",
      "[[0. 1. 2.]\n",
      " [3. 4. 5.]], shape=(2, 3), dtype=float32)\n",
      "a_3d  : tf.Tensor(\n",
      "[[[0. 1. 2.]\n",
      "  [3. 4. 5.]]], shape=(1, 2, 3), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a_3d = tf.expand_dims(a_2d, 0) # 2X3 크기의 2차원 행렬을 1X2X3 크기의 3차원 행렬로 변환\n",
    "print(\"a_2d     :\", a_2d)\n",
    "print(\"a_3d  :\", a_3d, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.18 마지막 차원 늘리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_3d     : tf.Tensor(\n",
      "[[[0. 1. 2.]\n",
      "  [3. 4. 5.]]], shape=(1, 2, 3), dtype=float32)\n",
      "a_4d  : tf.Tensor(\n",
      "[[[[0.]\n",
      "   [1.]\n",
      "   [2.]]\n",
      "\n",
      "  [[3.]\n",
      "   [4.]\n",
      "   [5.]]]], shape=(1, 2, 3, 1), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a_4d = tf.expand_dims(a_3d, 3) # 1X2X3 크기의 3차원 행렬을 1X2X3X1 크기의 4차원 행렬로 변환\n",
    "print(\"a_3d     :\", a_3d)\n",
    "print(\"a_4d  :\", a_4d, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.19 차원의 크기가 1인것 정리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_4d    : tf.Tensor(\n",
      "[[[[0.]\n",
      "   [1.]\n",
      "   [2.]]\n",
      "\n",
      "  [[3.]\n",
      "   [4.]\n",
      "   [5.]]]], shape=(1, 2, 3, 1), dtype=float32)\n",
      "a_1d    : tf.Tensor(\n",
      "[[0. 1. 2.]\n",
      " [3. 4. 5.]], shape=(2, 3), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a_1d = tf.squeeze(a_4d)\n",
    "print(\"a_4d    :\", a_4d)\n",
    "print(\"a_1d    :\", a_1d, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.20 텐서를 나누거나 합치는 명령"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.slice : 특정 부분을 추출\n",
    "- tf.split : 분할\n",
    "- tf.concat : 합치기\n",
    "- tf.tile : 복제-붙이기\n",
    "- tf.stack : 합성\n",
    "- tf.unstack : 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.21 또 연습용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]], dtype=int32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.reshape(tf.range(12), (3, 4))\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.22 슬라이스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 2, 3],\n",
       "       [5, 6, 7]], dtype=int32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.slice(a, [0, 1], [2, 3]) # (0, 1)위치에서 (2개, 3개)만큼 뽑아낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.23 가로축을 따라 2개로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 1]\n",
      " [4 5]\n",
      " [8 9]], shape=(3, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 2  3]\n",
      " [ 6  7]\n",
      " [10 11]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a1, a2 = tf.split(a, num_or_size_splits=2, axis=1) # 가로축(axis=1)을 따라 2개로 분할\n",
    "print(a1)\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.24 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]], dtype=int32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([a1, a2], 1) # 가로축(axis=1)을 따라 a1, a2를 합치기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.25 가로축 따라 세 개로 확대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 6), dtype=int32, numpy=\n",
       "array([[0, 1, 0, 1, 0, 1],\n",
       "       [4, 5, 4, 5, 4, 5],\n",
       "       [8, 9, 8, 9, 8, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(a1, [1,3]) # 가로축(axis=1)을 따라 3개로 복사-붙이기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.26 스택은 차원을 늘리면서 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
       "array([[[ 0,  1],\n",
       "        [ 4,  5],\n",
       "        [ 8,  9]],\n",
       "\n",
       "       [[ 2,  3],\n",
       "        [ 6,  7],\n",
       "        [10, 11]]], dtype=int32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3X2 행렬 a1, a2를 추가적인 차원으로 붙여서 2X3X2 고차원 텐서 생성\n",
    "a3 = tf.stack([a1, a2])\n",
    "a3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('tmp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d81af2821ad931ed5a8d864ba6e23cf7896a00e28685b62e5614689c1e8e2d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
